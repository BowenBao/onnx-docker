{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.  \n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 Image Classification using ONNX\n",
    "\n",
    "This example shows how to deploy the ResNet50 ONNX model as a web service using Azure Machine Learning services and the ONNX Runtime.\n",
    "\n",
    "## What is ONNX\n",
    "ONNX is an open format for representing machine learning and deep learning models. ONNX enables open and interoperable AI by enabling data scientists and developers to use the tools of their choice without worrying about lock-in and flexibility to deploy to a variety of platforms. ONNX is developed and supported by a community of partners including Microsoft, Facebook, and Amazon. For more information, explore the [ONNX website](http://onnx.ai).\n",
    "\n",
    "## ResNet50 Details\n",
    "ResNet classifies the major object in an input image into a set of 1000 pre-defined classes. For more information about the ResNet50 model and how it was created can be found on the [ONNX Model Zoo github](https://github.com/onnx/models/tree/master/models/image_classification/resnet). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import numpy as np    # we're going to use numpy to process input and output data\n",
    "import onnxruntime    # to inference ONNX models, we use the ONNX Runtime\n",
    "\n",
    "import onnx\n",
    "import glob\n",
    "from onnx import numpy_helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download pre-trained ONNX model from ONNX Model Zoo.\n",
    "\n",
    "Download the [ResNet50v2 model and test data](https://s3.amazonaws.com/onnx-model-zoo/resnet/resnet50v2/resnet50v2.tar.gz) and extract it in the same folder as this tutorial notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "onnx_model_url = \"https://s3.amazonaws.com/onnx-model-zoo/resnet/resnet50v2/resnet50v2.tar.gz\"\n",
    "urllib.request.urlretrieve(onnx_model_url, filename=\"resnet50v2.tar.gz\")\n",
    "\n",
    "labels_url = \"https://raw.githubusercontent.com/onnx/models/master/models/image_classification/synset.txt\"\n",
    "urllib.request.urlretrieve(labels, filename=\"synset.txt\")\n",
    "\n",
    "!tar xvzf resnet50v2.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"synset.txt\", 'rb') as label_file:\n",
    "    resnet_labels = np.array(label_file.read().splitlines())\n",
    "    \n",
    "resnet_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(img_data):\n",
    "    mean_vec = np.array([0.485, 0.456, 0.406])\n",
    "    stddev_vec = np.array([0.229, 0.224, 0.225])\n",
    "    norm_img_data = np.zeros(img_data.shape).astype('float32')\n",
    "    \n",
    "    # for each pixel in each channel, divide the value by 255 \n",
    "    # to get value between [0, 1] and then normalize\n",
    "    \n",
    "    for i in range(img_data.shape[0]):  \n",
    "        norm_img_data[i,:,:] = (img_data[i,:,:]/255 - mean_vec[i]) / stddev_vec[i]\n",
    "    return norm_img_data\n",
    "\n",
    "def postprocess(result):\n",
    "    prob = softmax(result)\n",
    "    prob = np.squeeze(prob)\n",
    "    a = np.argsort(prob)[::-1]\n",
    "    return a\n",
    "\n",
    "def softmax(x):\n",
    "    x = np.array(x).reshape(-1)\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference for ResNet using ONNX Runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = onnxruntime.InferenceSession('resnet50v2/resnet50v2.onnx', None)\n",
    "\n",
    "input_data_path = 'resnet50v2/test_data_set_0/input_0.pb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "from onnx import numpy_helper\n",
    "\n",
    "# load in our data which is expected as NCHW 224x224 image\n",
    "tensor = onnx.TensorProto()\n",
    "with open(input_data_path, 'rb') as f:\n",
    "    tensor.ParseFromString(f.read())\n",
    "    \n",
    "input_data = numpy_helper.to_array(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "input_name = session.get_inputs()[0].name  # get the id of the first input of the model\n",
    "result = session.run([], {input_name: input_data})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.take(resnet_labels,  postprocess(result)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_data_path = 'resnet50v2/test_data_set_0/output_0.pb'\n",
    "tensor = onnx.TensorProto()\n",
    "with open(output_data_path, 'rb') as f:\n",
    "    tensor.ParseFromString(f.read())\n",
    "    \n",
    "output_data = numpy_helper.to_array(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.testing.assert_almost_equal(output_data, result, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.take(resnet_labels,  postprocess(output_data)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = onnxruntime.InferenceSession('resnet50v2/resnet50v2.onnx', None)\n",
    "test_data_dir = 'resnet50v2/test_data_set_0'\n",
    "\n",
    "# Load inputs\n",
    "inputs = []\n",
    "inputs_num = len(glob.glob(os.path.join(test_data_dir, 'input_*.pb')))\n",
    "for i in range(inputs_num):\n",
    "    input_file = os.path.join(test_data_dir, 'input_{}.pb'.format(i))\n",
    "    tensor = onnx.TensorProto()\n",
    "    with open(input_file, 'rb') as f:\n",
    "        tensor.ParseFromString(f.read())\n",
    "    inputs.append(numpy_helper.to_array(tensor))\n",
    "\n",
    "# Load reference outputs\n",
    "ref_outputs = []\n",
    "ref_outputs_num = len(glob.glob(os.path.join(test_data_dir, 'output_*.pb')))\n",
    "for i in range(ref_outputs_num):\n",
    "    output_file = os.path.join(test_data_dir, 'output_{}.pb'.format(i))\n",
    "    tensor = onnx.TensorProto()\n",
    "    with open(output_file, 'rb') as f:\n",
    "        tensor.ParseFromString(f.read())\n",
    "    ref_outputs.append(numpy_helper.to_array(tensor))\n",
    "\n",
    "# Run the model on the backend\n",
    "input_name = session.get_inputs()[0].name  # get the id of the first input of the model\n",
    "outputs = [session.run([], {input_name: inputs[i]})[0] for i in range(inputs_num)]\n",
    "\n",
    "# Compare the results with reference outputs up to 4 decimal places\n",
    "for ref_o, o in zip(ref_outputs, outputs):\n",
    "    np.testing.assert_almost_equal(ref_o, o, 4)"
   ]
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "onnx"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
